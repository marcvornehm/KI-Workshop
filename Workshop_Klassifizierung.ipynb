{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be56ba7f-582e-47c8-ac26-93f6861b114e",
   "metadata": {},
   "source": [
    "# Workshop KI in der Medizin\n",
    "Wir trainieren unser eigenes neuronales Netzwerk um Bilder zu klassifizieren. Dazu können wir drei verschiedene Datensätze verwenden.\n",
    "In jedem Datensatz gibt es zwei Klassen, die wir jeweils mit `0` bzw. `1` definieren.\n",
    "Das Netzwerk bekommt dann ein Bild aus einer der beiden Klassen als Input und soll je nachdem eine `0` oder eine `1` ausgeben.\n",
    "\n",
    "##### 1. Kopf-MRT ohne oder mit Tumor\n",
    "Klasse `0`: Kein Tumor<br>\n",
    "Klasse `1`: Tumor<br>\n",
    "<span style=\"font-size:12px\">\n",
    "(Datensatzquelle: <a href=https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection>https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection</a>)\n",
    "</span>\n",
    "\n",
    "<img src=\"./bilder/notumorvstumor.png\" width=\"600\"/><br>\n",
    "\n",
    "##### 2. Herz-MRT in Lang- oder Kurzachse\n",
    "Klasse `0`: Langachsen<br>\n",
    "Klasse `1`: Kurzachsen<br>\n",
    "<span style=\"font-size:12px\">\n",
    "(Datensatzquelle: <a href=https://www.cardiacatlas.org/sunnybrook-cardiac-data>https://www.cardiacatlas.org/sunnybrook-cardiac-data</a>)\n",
    "</span>\n",
    "\n",
    "<img src=\"./bilder/laxvssax.png\" width=\"800\"/>\n",
    "\n",
    "##### 3. Katzen vs. Hunde\n",
    "Klasse `0`: Katzen<br>\n",
    "Klasse `1`: Hunde<br>\n",
    "<span style=\"font-size:12px\">\n",
    "(Datensatzquelle: <a href=https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification>https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification</a>)\n",
    "</span>\n",
    "\n",
    "<img src=\"./bilder/catsvsdogs.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung\n",
    "Der folgende Block muss nur einmal zu Beginn ausgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96ad5c-cb24-4aaf-8604-0f536fe0b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleclassifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28fbfed-cb74-4668-b285-0a502dd93fd7",
   "metadata": {},
   "source": [
    "## Netzwerkarchitektur\n",
    "Unsere Netzwerkarchitektur basiert auf einem sogenannten *LeNet*. Dabei handelt es sich um ein *Convolutional Neural Network*, das ist eine Klasse von neuronalen Netzen die sich sehr gut für die Bildverarbeitung eignet. Das *LeNet* beinhaltet drei Arten von Basisoperationen:\n",
    "1. Convolutional Layers (Bild-Operationen / Faltungen)\n",
    "2. Pooling Layers (Bildverkleinerung)\n",
    "3. Fully-connected Layers (Vektor-Operation)\n",
    "\n",
    "Nach Convolutional und Fully-connected Layers kann außerdem eine *Aktivierungsfunktion* eingefügt werden.\n",
    "\n",
    "### Convolutional Layer\n",
    "*Convolutions* (Faltungen) erlauben dem neuronalen Netz, sich auf kleinere Bereiche im Bild zu fokussieren und relevante Informationen daraus zu extrahieren. Die extrahierte Information ist ebenfalls in Form von Bildern gespeichert. Diese Bilder nennt man dann *Feature Maps*. In der Regel berechnet man aus dem selben Eingangsbild mehrere *Feature Maps*, welche dann alle an das nächste Layer weitergegeben werden.\n",
    "* `in_channels`: Anzahl der Feature Maps aus dem vorangehenden Convolution Layer. **Beim ersten Convolution Layer ist dieser Wert 1.**\n",
    "* `out_channels`: Anzahl der Feature Maps die durch die Convolution berechnet und an das nächste Layer weitergereicht werden.\n",
    "* `kernel_size`: Die Größe der Bereiche auf die sich das Netz bei der Convolution fokussieren soll. In der Regel ein ungerader Wert.\n",
    "* `activation`: Die Aktivierungsfunktion, die nach der Convolution verwendet werden soll (Erklärung siehe weiter unten).\n",
    "\n",
    "<img src=\"./bilder/conv.png\" width=\"1000\"/>\n",
    "\n",
    "### Pooling Layer\n",
    "*Pooling* erlaubt es dem neuronalen Netz, nur die relevantesten Inhalte der *Feature Maps* zu extrahieren und folglich nur diese für weitere Operationen zu verwenden. \n",
    "* `kernel_size`: Der Faktor, um den das Bild bzw. die Feature Map verkleinert werden soll.\n",
    "\n",
    "<img src=\"./bilder/pooling.png\" width=\"450\"/>\n",
    "\n",
    "### Fully-connected Layer\n",
    "*Fully-connected Layer* arbeiten auf ein-dimensionalen Vektoren. Jeder Wert in diesem Vektor (*Feature*) wird mit einem Gewicht multipliziert und aufsummiert um wiederum einen *Feature* zu berechnen. Dies kann man mit mehreren Sets von Gewichten wiederholen, um mehrere *Features* zu berechnen. \n",
    "* `in_features`: Anzahl der Eingangsfeatures.\n",
    "* `out_features`: Anzahl der berechneten Ausgangsfeatures. *Beim letzten Fully-connected Layer ist dieser Wert 1.*\n",
    "* `activation`: Die Aktivierungsfunktion, die nach dem Fully-connected Layer verwendet werden soll (Erklärung siehe weiter unten).\n",
    "\n",
    "<img src=\"./bilder/fcnn_.png\" width=\"350\"/>\n",
    "\n",
    "### Aktivierungsfunktion\n",
    "Aktivierungsfunktionen werden typischerweise auf die Resultate von Convolution und Fully-connected Layern angewandt. Sie erlauben es dem Netzwerk, komplexere (nichtlineare) Zusammenhänge zu erlernen. Ohne Aktivierungsfunktionen wäre das nur bedingt möglich. Außerdem können sie dazu verwendet werden, die Resultate einer vorausgegangenen Layer auf einen bestimmten Wertebereich zu beschränken.\n",
    "\n",
    "Arten:\n",
    "* `Relu`: Setzt den Wertebereich auf `[0, inf]`\n",
    "* `Sigmoid`: Setzt den Wertebereich auf `[0, 1]`\n",
    "* `Tanh`: Setzt den Wertebereich auf `[-1, 1]`\n",
    "* `NoActivation`: Keine Aktivierungsfunktion verwenden.\n",
    "\n",
    "<img src=\"./bilder/akt.png\" width=\"600\"/>\n",
    "\n",
    "### Lossfunktion\n",
    "Die Lossfunktion bewertet, wie gut unser Netzwerk vorhandene Trainingsdaten klassifiziert. Während des Trainings versucht das Netzwerk, diesen Wert zu minimieren​. Je niedriger dieser Wert, desto besser funktioniert das Netzwerk auf den Trainingsdaten.\n",
    "\n",
    "Es gibt viele verschiedene Arten von Lossfunktionen, welche oft für die Lösung bestimmter Problemklassen gedacht sind. Für unser Klassifikationsnetzwerk haben wir euch die Wahl der Lossfunktion abgenommen.\n",
    "\n",
    "### Jetzt du\n",
    "Unser Netzwerk besteht aus zwei Teilen. Im ersten Teil befinden sich nur Bildbasierte Operationen, also Convolutions und Poolings. Im zweiten Teil nur Fully-connected Layers.\n",
    "Im Folgenden kannst du dein Netzwerk parametrisieren. Verwende dazu folgende Schreibweise (ersetze dabei alle `?` durch deine Parameter):\n",
    "* für Convolutional Layers: `ConvolutionalLayer(in_channels=?, out_channels=?, kernel_size=?, activation=?)`\n",
    "* für Pooling Layers: `PoolingLayer(kernel_size=?)`\n",
    "* für Fully-connected Layers: `FullyConnectedLayer(in_features=?, out_features=?, activation=?)`\n",
    "\n",
    "Dabei müssen gelten:\n",
    "* `in_channels` des ersten Convolutional Layers muss `1` sein.\n",
    "* `out_channels` bzw. `in_channels` von aufeinander folgenden Convolutional Layers müssen gleich sein.\n",
    "* `in_features` des ersten Fully-connected Layers muss `flattened_features` sein (dieser Wert ergibt sich aus der Konfiguration des ersten Teils des Netzwerks - die Berechnung übernehmen wir im Hintergrund).\n",
    "* `out_features` bzw. `in_features` von aufeinander folgenden Fully-connected Layers müssen gleich sein.\n",
    "* `out_features` des letzten Fully-connected Layers muss `1` sein.\n",
    "\n",
    "Schreibe alle Convolutional und Pooling Layers jeweils durch ein Komma getrennt in die eckigen Klammern hinter `network_config_conv` und alle Fully Connected Layers in die eckigen Klammern hinter `network_config_fc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_config_conv = [\n",
    "    # Hier nur ConvolutionalLayer und PoolingLayer hinzufügen\n",
    "    ConvolutionalLayer(in_channels=1, out_channels=2, kernel_size=3, activation=NoActivation),\n",
    "    PoolingLayer(kernel_size=4),\n",
    "]\n",
    "flattened_features = compute_flattened_features(network_config_conv)  # <-- diese Zeile bitte nicht verändern!\n",
    "network_config_fc = [\n",
    "    # Hier nur FullyConnectedLayer hinzufügen\n",
    "    FullyConnectedLayer(in_features=flattened_features, out_features=1, activation=Sigmoid),\n",
    "]\n",
    "network = create_network(conv_config=network_config_conv, fc_config=network_config_fc)  # <-- diese Zeile bitte nicht verändern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz\n",
    "Hier laden wir unsere Daten für Netzwerktraining. Alle notwendigen Operationen dafür passieren im Hintergrund. Es kann allerdings die Anzahl an verwendeten Bilder der jeweiligen Klassen festgelegt werden.\n",
    "\n",
    "* Kopf-MRT ohne oder mit Tumor: `dataset = BrainTumorDataset(notumor=?, tumor=?)`\n",
    "  * max. Anzahl `notumor`: 88\n",
    "  * max. Anzahl `tumor`: 145\n",
    "* Herz-MRT in Lang- oder Kurzachse: `dataset = CardiacViewDataset(long_axes=?, short_axes=?)`\n",
    "  * max. Anzahl `long_axes`: 78\n",
    "  * max. Anzahl `short_axes`: 80\n",
    "* Katzen vs. Hunde: `dataset = CatsVsDogsDataset(cats=?, dogs=?)`\n",
    "  * max. Anzahl `cats`: 279\n",
    "  * max. Anzahl `dogs`: 278\n",
    "\n",
    "Um alle verfügbaren Bilder zu verwenden, kannst du die Parameter in den Klammern auch einfach weglassen (also z.B. `dataset = BrainTumorDataset()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainTumorDataset(notumor=50, tumor=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns einige (zufällige) Bilder aus dem Datensatz anschauen. Du kannst die folgende Zelle mehrfach ausführen, um andere Bilder zu sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.show_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Das Netzwerk ist erstellt und die Trainingsdaten sind geladen. Wir können also unser Training starten. Auch hier werden alle notwendigen Operationen im Hintergrund durchgeführt. Es kann allerdings die Anzahl an Trainingsepochen festgelegt werden. \n",
    "* `epochs`: Anzahl der verwendeten Trainingsepochen\n",
    "\n",
    "**Achtung:** Je mehr Epochen verwendet werden, desto länger dauert das Training. Viele Epochen sind nicht immer hilfreich!\n",
    "\n",
    "Übrigens: Wir verwenden im Hintergrund eine Grafikkarte. Dadurch geht das Training deutlich schneller. Falls du ausprobieren möchtest, wie viel Unterschied dies macht, kannst du `gpu=False` als Parameter hinzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network=network, dataset=dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testen\n",
    "Zuletzt testen wir unser Netzwerk auf Bildern, welches es während des Trainings nicht gesehen hat. In der folgenden Zelle musst du nichts ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(network=network, dataset_type=type(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "* Modifiziere das Netzwerk oder das Training so, dass es möglichst gute Testergebnisse liefert.\n",
    "* Welche Klassifizierungsaufgabe ist leichter, welche ist schwieriger?\n",
    "* Wie verändern sich die Testergebisse wenn man die Convolutional Layer weglässt?\n",
    "* Welche Einstellungen am Netzwerk oder Training waren besonders wichtig für gute Ergebnisse?\n",
    "\n",
    "## Experiment 2\n",
    "* Spiele mit der Anzahl Trainingsdaten herum.\n",
    "* Was passiert, wenn der Datensatz unausgewogen ist? (mehr Trainingsdaten einer Klasse)\n",
    "* Was passiert, wenn eine Klasse gar nicht im Trainingsdatensatz repräsentiert ist?\n",
    "* Was passiert, wenn insgesamt sehr wenige Daten zur Verfügung stehen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
